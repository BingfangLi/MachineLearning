# Decision tree

## Introduction 

Slitting datasets one feature at a time (making decision) and finally  doing a great job of classifying.

* Pros: Computationally cheap to use,easy for humans to understand learned results,missing values OK,can deal with irrelevant features
* Cons: Prone to overfitting

## principle

keywords:

* information gain
* entropy

It sounds  confusing ,but we only need to know is by calculating them we can split your data across every feature to see which split gives you the highest information gain.The split with the highest information gain is your best option.

## Application

Reference: https://www.jianshu.com/p/8aee00ab196d